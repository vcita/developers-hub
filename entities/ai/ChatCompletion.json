{
  "type": "object",
  "description": "Represents a chat completion response from an LLM provider. This entity follows the OpenAI-compatible response format (uses 'id' instead of 'uid' and 'created' as Unix timestamp instead of 'created_at' in ISO 8601) to maintain compatibility with the standard LLM provider response contract.",
  "properties": {
    "id": {
      "type": "string",
      "readOnly": true,
      "description": "Unique identifier for this completion, as returned by the LLM provider (e.g., \"chatcmpl-abc123\"). Note: uses 'id' instead of 'uid' to follow the OpenAI-compatible response format."
    },
    "object": {
      "type": "string",
      "readOnly": true,
      "description": "Object type identifier. Always 'chat.completion' for non-streaming responses.",
      "enum": ["chat.completion"]
    },
    "created": {
      "type": "integer",
      "readOnly": true,
      "description": "Unix timestamp (in seconds) of when the completion was created (e.g., 1677652288). Note: uses Unix timestamp instead of ISO 8601 to follow the OpenAI-compatible response format."
    },
    "model": {
      "type": "string",
      "readOnly": true,
      "description": "The model used for the completion in provider/model format (e.g., \"openai/gpt-4o-mini\", \"anthropic/claude-sonnet-4-5-20250929\")."
    },
    "choices": {
      "type": "array",
      "readOnly": true,
      "description": "Array of completion choices generated by the model. Typically contains a single choice.",
      "items": {
        "type": "object",
        "properties": {
          "index": {
            "type": "integer",
            "description": "Zero-based index of this choice in the choices array."
          },
          "message": {
            "type": "object",
            "properties": {
              "role": {
                "type": "string",
                "enum": ["assistant"],
                "description": "The role of the message author. Always 'assistant' for completion responses."
              },
              "content": {
                "type": "string",
                "nullable": true,
                "description": "The text content of the assistant's response. May be null when the model makes tool calls instead of generating text."
              },
              "tool_calls": {
                "type": "array",
                "description": "Tool calls requested by the assistant. Present when the model decides to call one or more functions defined in the request's 'tools' parameter.",
                "items": {
                  "type": "object",
                  "properties": {
                    "id": {
                      "type": "string",
                      "description": "Unique identifier for this tool call, used to match tool responses back to the call."
                    },
                    "type": {
                      "type": "string",
                      "enum": ["function"],
                      "description": "The type of tool call. Currently only 'function' is supported."
                    },
                    "function": {
                      "type": "object",
                      "properties": {
                        "name": {
                          "type": "string",
                          "description": "The name of the function the model wants to call."
                        },
                        "arguments": {
                          "type": "string",
                          "description": "A JSON-encoded string of the arguments to pass to the function."
                        }
                      }
                    }
                  }
                }
              }
            }
          },
          "finish_reason": {
            "type": "string",
            "enum": ["stop", "length", "tool_calls", "content_filter"],
            "description": "The reason the model stopped generating. 'stop' means the model naturally finished, 'length' means max_tokens was reached, 'tool_calls' means the model wants to call a function, 'content_filter' means content was filtered by safety systems."
          }
        }
      }
    },
    "usage": {
      "type": "object",
      "readOnly": true,
      "description": "Token usage statistics for the completion request. Useful for tracking costs and monitoring token consumption.",
      "properties": {
        "prompt_tokens": {
          "type": "integer",
          "description": "Number of tokens in the input prompt (e.g., 9)."
        },
        "completion_tokens": {
          "type": "integer",
          "description": "Number of tokens generated in the completion response (e.g., 9)."
        },
        "total_tokens": {
          "type": "integer",
          "description": "Total number of tokens used (prompt_tokens + completion_tokens) (e.g., 18)."
        }
      }
    }
  },
  "required": ["id", "object", "created", "model", "choices"],
  "example": {
    "id": "chatcmpl-abc123",
    "object": "chat.completion",
    "created": 1677652288,
    "model": "openai/gpt-4o-mini",
    "choices": [
      {
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "Hello! How can I help you today?"
        },
        "finish_reason": "stop"
      }
    ],
    "usage": {
      "prompt_tokens": 9,
      "completion_tokens": 9,
      "total_tokens": 18
    }
  }
}
